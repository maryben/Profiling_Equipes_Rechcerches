{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import spacy \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import unicodedata\n",
    "import inflect,gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import LsiModel\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(words):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stop_words and len(word)>2:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def remove_non_ascii(words):\n",
    "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_numbers(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if not word.isdigit():\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def normalize(words):\n",
    "    words = remove_non_ascii(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = remove_numbers(words)\n",
    "    words = remove_stopwords(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTokens(Text):\n",
    "    coumpound_nlp = nlp(Text)\n",
    "\n",
    "    coumpound_word = []\n",
    "    for X in coumpound_nlp.ents:\n",
    "        s = re.sub(r'[^\\w\\s]','',X.text.lower())\n",
    "        s = re.sub(\"[\\s.;:,*]+\", \" \", s)\n",
    "        coumpound_word.append(s)\n",
    "\n",
    "    tokens = word_tokenize(Text.lower())\n",
    "    fTokens = []\n",
    "    word = ''\n",
    "    for t in tokens:\n",
    "        if word == '':\n",
    "            word = t\n",
    "        else:\n",
    "            word += ' '+t\n",
    "        find = False\n",
    "        for X in coumpound_word:\n",
    "            if word in X:\n",
    "                find = True\n",
    "                if word == X:\n",
    "                    fTokens.append(word)\n",
    "                    word = ''\n",
    "                    break\n",
    "        if find == False:\n",
    "            tokensW = word_tokenize(word)\n",
    "            for w in tokensW:\n",
    "                fTokens.append(w)\n",
    "            word = ''\n",
    "    fTokens = normalize(fTokens)\n",
    "    return fTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import words as engwords\n",
    "def getTokens_withoutNames(Text):\n",
    "    coumpound_nlp = nlp(Text)\n",
    "\n",
    "    tokens = normalize(word_tokenize(Text.lower()))\n",
    "    fTokens = []\n",
    "    word = ''\n",
    "    for t in tokens:\n",
    "        find = False\n",
    "        for X in coumpound_nlp.ents:\n",
    "            if t in X.text.lower():\n",
    "                if X.label_ != 'PERSON':\n",
    "                    find = True\n",
    "                    break;\n",
    "        if find == False:\n",
    "            if t in engwords.words():\n",
    "                fTokens.append(t)\n",
    "    return fTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from textblob import TextBlob as tb\n",
    "\n",
    "def tf(word, words):\n",
    "    return words.count(word) / len(words)\n",
    "\n",
    "def n_containing(word, wordslist):\n",
    "    return sum(1 for words in wordslist if word in words)\n",
    "\n",
    "def idf(word, wordslist):\n",
    "    return math.log(len(wordslist) / (1 + n_containing(word, wordslist)))\n",
    "\n",
    "def tfidf(word, words, wordslist):\n",
    "    return tf(word, words) * idf(word, wordslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traitement1(line):\n",
    "    words = getTokens(line[1])\n",
    "    print(\"Top interest :\")\n",
    "    scores = {word: tf(word, words) for word in words}\n",
    "    sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    for word, score in sorted_words[:3]:\n",
    "        print(\"\\tWord: {}, TF: {}\".format(word, round(score, 5)))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traitement(line):\n",
    "    \n",
    "    words = getTokens(line[1])\n",
    "    print(\"Top interest :\")\n",
    "    scores = {word: tf(word, words) for word in words}\n",
    "    sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    for word, score in sorted_words[:3]:\n",
    "        print(\"\\tWord: {}, TF: {}\".format(word, round(score, 5)))\n",
    "    \n",
    "    line2 = nlp(line[2])\n",
    "    print(\"University :\")\n",
    "    for X in line2.ents:\n",
    "        if 'University' in X.text: \n",
    "            print(\"\\t\"+X.text.replace('\\n',' '))\n",
    "    \n",
    "    print(\"Advisors :\")\n",
    "    for X in line2.ents:\n",
    "        if X.label_ == 'PERSON':\n",
    "            print(\"\\t\"+X.text.replace('\\n',' '))\n",
    "    \n",
    "    print(\"laboratories or research teams\")\n",
    "    line3 = nlp(line[3])\n",
    "    for X in line3.ents:\n",
    "        if X.label_ == 'ORG':\n",
    "            print(\"\\t\"+X.text.replace('\\n',' '))\n",
    "    \n",
    "    print(\"collaborations\")\n",
    "    line4 = nlp(line[4])\n",
    "    collaborations = []\n",
    "    for X in line4.ents:\n",
    "        if X.label_ == 'PERSON':\n",
    "            find = False\n",
    "            for c in collaborations:\n",
    "                if X.text in c:\n",
    "                    find = True\n",
    "            if find == False:\n",
    "                collaborations.append(X.text.replace(\"[\\s]+\",' '))\n",
    "\n",
    "    for c in collaborations:\n",
    "        print(\"\\t\"+c)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Lu Jiang \n",
      "Top interest :\n",
      "\tWord: research, TF: 0.06667\n",
      "\tWord: big data, TF: 0.06667\n",
      "\tWord: goal, TF: 0.03333\n",
      "University :\n",
      "\tCarnegie Mellon University\n",
      "\tFree University of Brussels\n",
      "\tXi’an Jiaotong University\n",
      "Advisors :\n",
      "\tAlexander Hauptmann\n",
      "\tTeruko Mitamura\n",
      "\tMultimedia Search\n",
      "\tRank\n",
      "\tJun Liu B.Eng\n",
      "\tGPA\n",
      "laboratories or research teams\n",
      "\tGoogle AI Cloud\n",
      "\tCarnegie Mellon University\n",
      "\tIARPA\n",
      "\tNIST TRECVID\n",
      "\tYahoo Research\n",
      "\tGoogle Research\n",
      "\tYouTube\n",
      "\tMicrosoft\n",
      "\tXi’an Jiaotong University\n",
      "\tPDF\n",
      "\tHTML\n",
      "collaborations\n",
      "\tLu Jiang\n",
      "\tZhengyuan Zhou\n",
      "\tThomas Leung\n",
      "\tLi-Jia Li\n",
      "\tLi Fei-Fei\n",
      "\tJunwei Liang\n",
      "\tLiangliang Cao\n",
      "\tAlexander Hauptmann\n",
      "\tZelun Luo\n",
      "\tJun-Ting Hsieh\n",
      "\tJuan Carlos Niebles\n",
      "\tYu Wu\n",
      "\tLinchao Zhu\n",
      "\tYi Yang\n",
      "\tDecoupled Novel\n",
      "\tYannis Kalantidis\n",
      "\tJiliang Tang\n",
      "\tAlex Hauptmann\n",
      "\tDeyu Meng\n",
      "\tPrior Knowledge\n",
      "\tICMR\n",
      "\tJunwei Han\n",
      "\tSenmao Ye\n",
      "\tXiaojun Chang\n",
      "\tMultimedia Search\n",
      "\tTeruko Mitamura\n",
      "\tVideos\n",
      "\tQian Zhao\n",
      "\tQi Xie\n",
      "\tZongben Xu\n",
      "\tDingwen Zhang\n",
      "\tLi Chao\n",
      "\tZhao Qian\n",
      "\tShoou\n",
      "\tZhen-Zhong\n",
      "\n",
      "JUAN GARCIA \n",
      "Top interest :\n",
      "\tWord: investigations, TF: 0.11111\n",
      "\tWord: improve, TF: 0.11111\n",
      "\tWord: seismic, TF: 0.11111\n",
      "University :\n",
      "\tUniversity of Illinois\n",
      "\tUniversity National de San Juan\n",
      "Advisors :\n",
      "\tTed S. Visor\n",
      "laboratories or research teams\n",
      "\tDepartment of Civil Engineering\n",
      "\tUniversity of Illinois\n",
      "\tthe City Planning Department\n",
      "\tFEMA\n",
      "collaborations\n",
      "\tGarcia\n",
      "\n",
      "ROBERT BROADSTONE\n",
      "Top interest :\n",
      "\tWord: conservation, TF: 0.05357\n",
      "\tWord: research, TF: 0.03571\n",
      "\tWord: government, TF: 0.03571\n",
      "University :\n",
      "\tUniversity of Carmarthen\n",
      "Advisors :\n",
      "\tF Smith\n",
      "laboratories or research teams\n",
      "collaborations\n",
      "\n",
      "Abi Demir\n",
      "Top interest :\n",
      "\tWord: firm, TF: 0.03704\n",
      "\tWord: abi, TF: 0.01852\n",
      "\tWord: interested, TF: 0.01852\n",
      "University :\n",
      "\tHarvard University\n",
      "\tNanyang Technological University\n",
      "\tUniversity of Melbourne\n",
      "Advisors :\n",
      "laboratories or research teams\n",
      "\tGraduate Researcher 2012\n",
      "\tNanyang Technological University\n",
      "\tNCP\n",
      "\tNCP\n",
      "\tOrigin\n",
      "collaborations\n",
      "\tF Wang\n",
      "\tG Li\n",
      "\tCurrie\n",
      "\tJohnson\n",
      "\tHeterochromatin\n",
      "\tNV Berezhnoy\n",
      "\tD Lundberg\n",
      "\tN Korolev\n",
      "\tJ Yan\n",
      "\tM Miguel\n",
      "\tY Liu\n",
      "\tY Yang\n",
      "\tYP Fan\n",
      "\tL Nordenskiöld\n",
      "\tCJ Su\n",
      "\n",
      "Akila Arap\n",
      "Top interest :\n",
      "\tWord: akila, TF: 0.0625\n",
      "\tWord: also, TF: 0.0625\n",
      "\tWord: firm, TF: 0.0625\n",
      "University :\n",
      "\tHarvard University\n",
      "\tCambridge University\n",
      "\tUniversity of Oxford\n",
      "Advisors :\n",
      "\tMerit Fellowship\n",
      "laboratories or research teams\n",
      "\tHarvard University\n",
      "\tCambridge University\n",
      "collaborations\n",
      "\tScience Signaling\n",
      "\n",
      "Sachi Nabulsi \n",
      "Top interest :\n",
      "\tWord: data, TF: 0.125\n",
      "\tWord: sachi, TF: 0.0625\n",
      "\tWord: applying, TF: 0.0625\n",
      "University :\n",
      "\tHarvard University\n",
      "\tUniversity of Oxford\n",
      "\tStanford University Stanford\n",
      "Advisors :\n",
      "\tM.Phil\n",
      "\tAxline\n",
      "laboratories or research teams\n",
      "\tMatLab  \n",
      "\tUniversity of Oxford\n",
      "\tMatLab \n",
      "\tStanford University Stanford\n",
      "\tEuropean Organisation for Nuclear Research\n",
      "\tCERN\n",
      "\tCERN\n",
      "\tStanford University\n",
      "collaborations\n",
      "\tS. Nabulsi\n",
      "\n",
      "JUANITA DUARTE\n",
      "Top interest :\n",
      "\tWord: modern, TF: 0.2\n",
      "\tWord: military, TF: 0.2\n",
      "\tWord: history, TF: 0.2\n",
      "University :\n",
      "\tUniversity of Toronto\n",
      "\tUniversity of Toronto\n",
      "\tUniversity of Alberta\n",
      "Advisors :\n",
      "\tMichael Faust\n",
      "\tEdward Chelin\n",
      "laboratories or research teams\n",
      "\tUniversity of Toronto\n",
      "\tDefence White Paper\n",
      "\tGraduate Student\n",
      "\tDepartment of History, University of Toronto\n",
      "collaborations\n",
      "\tDuarte\n",
      "\tJuanita\n",
      "\n",
      "Beverly Gilmore\n",
      "Top interest :\n",
      "\tWord: information, TF: 0.11111\n",
      "\tWord: management, TF: 0.11111\n",
      "\tWord: data, TF: 0.11111\n",
      "University :\n",
      "\tUniversity of Toronto\n",
      "\tUniversity of Toronto\n",
      "\tUniversity of Toronto\n",
      "Advisors :\n",
      "\tElizabeth Strom\n",
      "laboratories or research teams\n",
      "\tOntario Society for Medical Laboratory\n",
      "\tOntario Institute for Studies\n",
      "\tEducation\n",
      "\tUniversity of Toronto\n",
      "\tthe Canadian Society for the Study of Higher Education\n",
      "\tOntario Institute for Studies\n",
      "\tEducation\n",
      "\tUniversity of Toronto\n",
      "\tInstitute for Women’s Studies\n",
      "\tGender Studies\n",
      "\tUniversity of Toronto\n",
      "\tEquity Studies\n",
      "\tEducation\n",
      "\tOISE\n",
      "\tUT\n",
      "\tSSHRC\n",
      "\tthe Centre for the Study of Education and Work\n",
      "collaborations\n",
      "\tGilmore\n",
      "\tB.\n",
      "\tM. Suzin\n",
      "\tS. H. Tran\n",
      "\tEds\n",
      "\tTeaching\n",
      "\tKingston\n",
      "\t98–111\n",
      "\n",
      "Monir El Halaby\n",
      "Top interest :\n",
      "\tWord: optical, TF: 0.19231\n",
      "\tWord: wireless, TF: 0.11538\n",
      "\tWord: channels, TF: 0.11538\n",
      "University :\n",
      "\tUniversity of Toronto\n",
      "\tUniversity of Toronto\n",
      "\tUniversity of Waterloo   \n",
      "Advisors :\n",
      "\tFinn Ginsberry\n",
      "\tProfessors Dieter Kohlberg\n",
      "\tFinn Ginsberry\n",
      "laboratories or research teams\n",
      "\tUniversity of Toronto  Project\n",
      "\tMaster’s\n",
      "\tDepartment of Electrical and Computer Engineering\n",
      "\tUniversity of Toronto  Project\n",
      "\tVTSL Research Group\n",
      "\tDepartment of Electrical and Computer Engineering\n",
      "\tUniversity of Waterloo Project:\n",
      "\tSupervisors\n",
      "\tUndergraduate Research Assistantship\n",
      "\tDepartment of Electrical and Computer Engineering\n",
      "\tUniversity of Waterloo  Project: Research\n",
      "\tB.A. Fuentes\n",
      "collaborations\n",
      "\tGinsberry\n",
      "\n",
      "\n",
      "Sandeep Mehta\n",
      "\n",
      "Top interest :\n",
      "\tWord: antibody, TF: 0.16\n",
      "\tWord: responses, TF: 0.08\n",
      "\tWord: antibodies, TF: 0.08\n",
      "University :\n",
      "\tUniversity of Toronto\n",
      "\tMcMaster University\n",
      "Advisors :\n",
      "\tOntario  \n",
      "\tHonours Bachelor\n",
      "\tHamilton\n",
      "laboratories or research teams\n",
      "\tDepartment of Immunology\n",
      "\tUniversity of Toronto\n",
      "\tCangen Research Institute\n",
      "\tUndergraduate Research\n",
      "\tDepartment of Biology, University of Toronto   Organized\n",
      "collaborations\n",
      "\tMehta\n",
      "\tCutler\n",
      "\tB. H. (\n",
      "\tHuman Retroviruses\n",
      "\tB. H. (2008\n",
      "\n",
      "JAIME  SIMONELL\n",
      "Top interest :\n",
      "\tWord: cognitive, TF: 0.09091\n",
      "\tWord: work, TF: 0.09091\n",
      "\tWord: analysis, TF: 0.09091\n",
      "University :\n",
      "\tUniversity of Toronto\n",
      "\tUniversity of Waterloo, Computer Science\n",
      "Advisors :\n",
      "\tCarine Mendelsson  Bachelor\n",
      "laboratories or research teams\n",
      "\tDepartment of Industrial Engineering\n",
      "\tUniversity of Toronto\n",
      "\tResearch Assistant Department of Computer Science\n",
      "\tUniversity of Waterloo\n",
      "\tVisual Perception and Interface Design\n",
      "\tResearch Assistant Department of Mathematics, University of Waterloo\n",
      "\tMathematical\n",
      "collaborations\n",
      "\tSimonell\n",
      "\n",
      "Leslie Winters\n",
      "Top interest :\n",
      "\tWord: conducted, TF: 0.07692\n",
      "\tWord: ethical, TF: 0.07692\n",
      "\tWord: review, TF: 0.07692\n",
      "University :\n",
      "\tUniversity of Toronto\n",
      "\tMcGill University\n",
      "\tQueens University\n",
      "Advisors :\n",
      "\tM.Ed\n",
      "\tSettings  \n",
      "\tJames Strong\n",
      "\tBiology\n",
      "laboratories or research teams\n",
      "\tLanguage Competency Program  \n",
      "\tLanguage Planning Course\n",
      "collaborations\n",
      "\tManson\n",
      "\tN. et L. Winters\n",
      "\tVieillex\n",
      "\tS. et J. Robert\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import csv\n",
    "with open('CVs.csv', 'r', encoding=\"utf-8\") as f:\n",
    "    theReader = csv.reader(f)\n",
    "    processed_words = [] \n",
    "    publications = []\n",
    "    done = False\n",
    "    for line in theReader:\n",
    "        if done:\n",
    "            print(\"\\n\"+line[0])\n",
    "            lwords = traitement(line)\n",
    "            publications.append(line[4])\n",
    "        else:\n",
    "            done = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = []\n",
    "\n",
    "for doc in publications:\n",
    "    processed_docs.append(getTokens_withoutNames(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary.filter_extremes(no_below=15, no_above=0.1, keep_n= 100000)\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "lda_model =  gensim.models.LdaMulticore(bow_corpus, \n",
    "                                   num_topics = 7, \n",
    "                                   id2word = dictionary,                                    \n",
    "                                   passes = 10,\n",
    "                                   workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.043*\"cutler\" + 0.043*\"cell\" + 0.043*\"professional\" + 0.023*\"noise\" + 0.023*\"constrained\" + 0.023*\"capable\" + 0.023*\"human\" + 0.023*\"antibody\" + 0.023*\"conformation\" + 0.023*\"immunogenic\"\n",
      "\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.105*\"conservation\" + 0.072*\"economist\" + 0.038*\"model\" + 0.038*\"south\" + 0.038*\"analysis\" + 0.038*\"towards\" + 0.038*\"economy\" + 0.038*\"environment\" + 0.005*\"professional\" + 0.005*\"entry\"\n",
      "\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.096*\"title\" + 0.073*\"year\" + 0.050*\"issue\" + 0.050*\"produced\" + 0.050*\"manuscript\" + 0.050*\"page\" + 0.050*\"volume\" + 0.027*\"soft\" + 0.027*\"oppositely\" + 0.027*\"matter\"\n",
      "\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.051*\"liang\" + 0.026*\"oral\" + 0.026*\"artificial\" + 0.026*\"detection\" + 0.014*\"optical\" + 0.014*\"portrait\" + 0.014*\"power\" + 0.014*\"intensity\" + 0.014*\"parle\" + 0.014*\"capacity\"\n",
      "\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.081*\"chromatin\" + 0.042*\"cationic\" + 0.042*\"histone\" + 0.022*\"terminus\" + 0.022*\"influence\" + 0.022*\"domain\" + 0.022*\"winged\" + 0.022*\"amino\" + 0.022*\"organization\" + 0.022*\"yan\"\n",
      "\n",
      "\n",
      "Topic: 5 \n",
      "Words: 0.057*\"interwar\" + 0.007*\"chromatin\" + 0.007*\"cationic\" + 0.007*\"histone\" + 0.007*\"assembly\" + 0.007*\"density\" + 0.007*\"yang\" + 0.007*\"membrane\" + 0.007*\"heterochromatin\" + 0.007*\"charge\"\n",
      "\n",
      "\n",
      "Topic: 6 \n",
      "Words: 0.008*\"chromatin\" + 0.008*\"histone\" + 0.008*\"cationic\" + 0.008*\"preparation\" + 0.008*\"protein\" + 0.008*\"silent\" + 0.008*\"model\" + 0.008*\"wang\" + 0.008*\"density\" + 0.008*\"helix\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic ))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
